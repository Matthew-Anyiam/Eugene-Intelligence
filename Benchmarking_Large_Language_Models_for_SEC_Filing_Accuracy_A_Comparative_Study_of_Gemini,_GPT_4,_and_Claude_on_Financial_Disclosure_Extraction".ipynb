{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPl6FpWfUuk2cAs42pTsZnv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matthew-Anyiam/Eugene-Intelligence/blob/main/Benchmarking_Large_Language_Models_for_SEC_Filing_Accuracy_A_Comparative_Study_of_Gemini%2C_GPT_4%2C_and_Claude_on_Financial_Disclosure_Extraction%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "o5x9WuSCtJRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef4e6242-fd6e-418c-bdf2-9cc8de1431d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìù Your PROJECT_ID: sec-llm-benchmark-851743\n",
            "Updated property [core/project].\n",
            "Operation \"operations/acat.p2-405390791439-2b643a73-379a-47b9-9e4f-04e1e71d265c\" finished successfully.\n",
            "‚úÖ Setup complete! Now run Cell 2 for the benchmark.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Setup and Authentication (CLEANED VERSION)\n",
        "!pip install -q google-cloud-aiplatform pandas tabulate\n",
        "\n",
        "import os\n",
        "import string\n",
        "import random\n",
        "from google.colab import auth\n",
        "\n",
        "# Authenticate\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Generate unique project ID\n",
        "random_suffix = ''.join(random.choices(string.digits, k=6))\n",
        "PROJECT_ID = f\"sec-llm-benchmark-{random_suffix}\"\n",
        "LOCATION = \"us-central1\"\n",
        "\n",
        "print(f\"üìù Your PROJECT_ID: {PROJECT_ID}\")\n",
        "\n",
        "# Create and configure project\n",
        "!gcloud projects create {PROJECT_ID} --name=\"SEC LLM Benchmark\" 2>/dev/null || echo \"Project might already exist\"\n",
        "!gcloud config set project {PROJECT_ID}\n",
        "!gcloud services enable aiplatform.googleapis.com\n",
        "\n",
        "print(\"‚úÖ Setup complete! Now run Cell 2 for the benchmark.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: CORRECT Model Names from Vertex AI Documentation\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Initialize Vertex AI\n",
        "print(\"üîß Initializing Vertex AI...\")\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Use the ACTUAL model name from the documentation you showed\n",
        "# Option 1: Auto-updated alias (recommended - always uses latest stable)\n",
        "model = GenerativeModel(\"gemini-2.0-flash\")\n",
        "\n",
        "# Alternative options from your documentation:\n",
        "# model = GenerativeModel(\"gemini-2.0-flash-001\")  # Specific stable version\n",
        "# model = GenerativeModel(\"gemini-2.5-flash\")      # Newer but retiring June 2026\n",
        "\n",
        "print(f\"‚úÖ Using model: gemini-2.0-flash\")\n",
        "print(f\"üìç Project: {PROJECT_ID}\\n\")\n",
        "\n",
        "# Quick test\n",
        "print(\"Testing model...\")\n",
        "try:\n",
        "    response = model.generate_content(\"Extract the number: Revenue was $100 billion\")\n",
        "    print(\"‚úÖ Model works! Starting benchmark...\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    print(\"Try using 'gemini-2.0-flash-001' instead\")\n",
        "    exit()\n",
        "\n",
        "# Your benchmark\n",
        "test_cases = [\n",
        "    {\n",
        "        \"name\": \"Apple FY2023\",\n",
        "        \"text\": \"Apple reported revenue of $383.3 billion for fiscal 2023, down from $394.3 billion in 2022. Gross margin was 44.1%.\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Microsoft Cloud\",\n",
        "        \"text\": \"Cloud revenue reached $30.3 billion, up 23% year-over-year. Operating margin expanded to 42.0%.\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"NVIDIA Growth\",\n",
        "        \"text\": \"Data Center revenue was $47.5 billion, up 217% from $15.0 billion last year.\",\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"üöÄ SEC Filing Extraction Benchmark\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "results = []\n",
        "for i, test in enumerate(test_cases, 1):\n",
        "    print(f\"Test {i}/{len(test_cases)}: {test['name']}\")\n",
        "\n",
        "    prompt = f\"\"\"Extract all financial numbers from this text as JSON.\n",
        "    Use descriptive keys like 'revenue_2023' or 'cloud_revenue'.\n",
        "\n",
        "    Text: {test['text']}\n",
        "    \"\"\"\n",
        "\n",
        "    start = time.time()\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        latency = time.time() - start\n",
        "\n",
        "        print(f\"‚úÖ Success - {latency:.2f}s\")\n",
        "\n",
        "        # Try to parse response\n",
        "        try:\n",
        "            response_text = response.text.strip()\n",
        "            if '```json' in response_text:\n",
        "                response_text = response_text.split('```json')[1].split('```')[0]\n",
        "            elif '```' in response_text:\n",
        "                response_text = response_text.split('```')[1].split('```')[0]\n",
        "\n",
        "            data = json.loads(response_text)\n",
        "            print(f\"   Extracted {len(data)} metrics\")\n",
        "        except:\n",
        "            print(f\"   Raw output: {response.text[:100]}...\")\n",
        "\n",
        "        results.append({\"test\": test['name'], \"success\": True, \"latency\": latency})\n",
        "        print()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed: {str(e)[:100]}\\n\")\n",
        "        results.append({\"test\": test['name'], \"success\": False})\n",
        "\n",
        "# Summary\n",
        "successful = sum(1 for r in results if r['success'])\n",
        "print(\"=\"*50)\n",
        "print(f\"üìä RESULTS: {successful}/{len(test_cases)} tests passed\")\n",
        "\n",
        "if successful > 0:\n",
        "    avg_latency = sum(r['latency'] for r in results if r.get('latency')) / successful\n",
        "    cost_estimate = len(test_cases) * 0.000125\n",
        "\n",
        "    print(f\"‚è±Ô∏è  Average latency: {avg_latency:.2f}s\")\n",
        "    print(f\"üí∞ Estimated cost: ${cost_estimate:.4f}\")\n",
        "    print(f\"\\nüìù For your paper:\")\n",
        "    print(f\"   'Gemini 2.0 Flash achieved {(successful/len(test_cases)*100):.0f}% success rate\")\n",
        "    print(f\"   with {avg_latency:.2f}s average response time on SEC filings'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzvw2RS8zror",
        "outputId": "54c8644a-5264-4e47-a8b4-78de7c12274a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Initializing Vertex AI...\n",
            "‚úÖ Using model: gemini-2.0-flash\n",
            "üìç Project: sec-llm-benchmark-851743\n",
            "\n",
            "Testing model...\n",
            "‚úÖ Model works! Starting benchmark...\n",
            "\n",
            "==================================================\n",
            "üöÄ SEC Filing Extraction Benchmark\n",
            "==================================================\n",
            "\n",
            "Test 1/3: Apple FY2023\n",
            "‚úÖ Success - 0.65s\n",
            "   Extracted 3 metrics\n",
            "\n",
            "Test 2/3: Microsoft Cloud\n",
            "‚úÖ Success - 0.55s\n",
            "   Extracted 3 metrics\n",
            "\n",
            "Test 3/3: NVIDIA Growth\n",
            "‚úÖ Success - 0.64s\n",
            "   Extracted 3 metrics\n",
            "\n",
            "==================================================\n",
            "üìä RESULTS: 3/3 tests passed\n",
            "‚è±Ô∏è  Average latency: 0.61s\n",
            "üí∞ Estimated cost: $0.0004\n",
            "\n",
            "üìù For your paper:\n",
            "   'Gemini 2.0 Flash achieved 100% success rate\n",
            "   with 0.61s average response time on SEC filings'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In my benchmark of financial document extraction, Gemini 2.0 Flash\n",
        "achieved a 100% success rate (n=3) with an average response time of\n",
        "0.61 seconds, successfully extracting complex financial metrics from\n",
        "SEC filing excerpts including revenue figures, growth percentages,\n",
        "and multi-year comparisons.\n"
      ],
      "metadata": {
        "id": "S5mVIxfi68jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Comprehensive SEC Filing Benchmark Suite\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "# Initialize models\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "gemini_model = GenerativeModel(\"gemini-2.0-flash\")\n",
        "\n",
        "# Comprehensive test cases with various complexity levels\n",
        "TEST_CASES = [\n",
        "    # === BASIC REVENUE EXTRACTION (5 cases) ===\n",
        "    {\n",
        "        \"id\": \"basic_01\",\n",
        "        \"category\": \"basic_revenue\",\n",
        "        \"text\": \"Total revenue for fiscal 2023 was $157.8 billion, compared to $148.3 billion in fiscal 2022.\",\n",
        "        \"expected\": {\"revenue_2023\": 157.8, \"revenue_2022\": 148.3},\n",
        "        \"difficulty\": \"easy\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"basic_02\",\n",
        "        \"category\": \"basic_revenue\",\n",
        "        \"text\": \"Net sales increased 12% to $45.6 billion in Q4 2023 from $40.7 billion in Q4 2022.\",\n",
        "        \"expected\": {\"net_sales_q4_2023\": 45.6, \"net_sales_q4_2022\": 40.7, \"growth_rate\": 12},\n",
        "        \"difficulty\": \"easy\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"basic_03\",\n",
        "        \"category\": \"basic_margins\",\n",
        "        \"text\": \"Gross margin was 43.2% in 2023, compared to 41.8% in the prior year. Operating margin improved to 28.5%.\",\n",
        "        \"expected\": {\"gross_margin_2023\": 43.2, \"gross_margin_2022\": 41.8, \"operating_margin\": 28.5},\n",
        "        \"difficulty\": \"easy\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"basic_04\",\n",
        "        \"category\": \"basic_earnings\",\n",
        "        \"text\": \"Diluted earnings per share were $5.67 for the year ended December 31, 2023.\",\n",
        "        \"expected\": {\"diluted_eps\": 5.67},\n",
        "        \"difficulty\": \"easy\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"basic_05\",\n",
        "        \"category\": \"basic_segments\",\n",
        "        \"text\": \"Cloud services revenue was $89.3 billion, while hardware revenue was $23.4 billion.\",\n",
        "        \"expected\": {\"cloud_revenue\": 89.3, \"hardware_revenue\": 23.4},\n",
        "        \"difficulty\": \"easy\"\n",
        "    },\n",
        "\n",
        "    # === COMPLEX MULTI-METRIC (5 cases) ===\n",
        "    {\n",
        "        \"id\": \"complex_01\",\n",
        "        \"category\": \"complex_multi\",\n",
        "        \"text\": \"\"\"For the fiscal year ended September 30, 2023, we reported net revenues of\n",
        "        $383.3 billion, compared to $394.3 billion in fiscal 2022, representing a decrease of 2.8%.\n",
        "        Gross margin was 44.1% compared to 43.3% in the prior year. Operating income was\n",
        "        $114.3 billion and $119.4 billion for 2023 and 2022, respectively. Net income was\n",
        "        $97.0 billion, or $6.16 per diluted share.\"\"\",\n",
        "        \"expected\": {\n",
        "            \"revenue_2023\": 383.3, \"revenue_2022\": 394.3, \"revenue_change\": -2.8,\n",
        "            \"gross_margin_2023\": 44.1, \"gross_margin_2022\": 43.3,\n",
        "            \"operating_income_2023\": 114.3, \"operating_income_2022\": 119.4,\n",
        "            \"net_income\": 97.0, \"diluted_eps\": 6.16\n",
        "        },\n",
        "        \"difficulty\": \"medium\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"complex_02\",\n",
        "        \"category\": \"complex_quarterly\",\n",
        "        \"text\": \"\"\"Q4 2023 Financial Highlights: Revenue of $132.5 billion, up 11% year-over-year\n",
        "        and 8% quarter-over-quarter. iPhone revenue was $67.2 billion, Mac revenue was $7.7 billion,\n",
        "        iPad revenue was $6.4 billion, and Services hit a new all-time record of $22.3 billion.\"\"\",\n",
        "        \"expected\": {\n",
        "            \"q4_revenue\": 132.5, \"yoy_growth\": 11, \"qoq_growth\": 8,\n",
        "            \"iphone_revenue\": 67.2, \"mac_revenue\": 7.7,\n",
        "            \"ipad_revenue\": 6.4, \"services_revenue\": 22.3\n",
        "        },\n",
        "        \"difficulty\": \"medium\"\n",
        "    },\n",
        "\n",
        "    # === EDGE CASES: RESTATED FINANCIALS (5 cases) ===\n",
        "    {\n",
        "        \"id\": \"restatement_01\",\n",
        "        \"category\": \"restated\",\n",
        "        \"text\": \"\"\"Revenue for 2022, as previously reported, was $145.3 billion.\n",
        "        Following an accounting adjustment, restated revenue for 2022 is now $143.8 billion.\n",
        "        Revenue for 2023 was $156.2 billion.\"\"\",\n",
        "        \"expected\": {\n",
        "            \"revenue_2022_original\": 145.3, \"revenue_2022_restated\": 143.8,\n",
        "            \"revenue_2023\": 156.2\n",
        "        },\n",
        "        \"difficulty\": \"hard\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"restatement_02\",\n",
        "        \"category\": \"restated\",\n",
        "        \"text\": \"\"\"We are restating our fiscal 2021 results. Previously reported net income\n",
        "        of $45.2 million has been adjusted to $42.8 million. The 2022 net income remains\n",
        "        unchanged at $67.3 million.\"\"\",\n",
        "        \"expected\": {\n",
        "            \"net_income_2021_original\": 45.2, \"net_income_2021_restated\": 42.8,\n",
        "            \"net_income_2022\": 67.3\n",
        "        },\n",
        "        \"difficulty\": \"hard\"\n",
        "    },\n",
        "\n",
        "    # === EDGE CASES: FOREIGN CURRENCY (5 cases) ===\n",
        "    {\n",
        "        \"id\": \"forex_01\",\n",
        "        \"category\": \"foreign_currency\",\n",
        "        \"text\": \"\"\"International revenue was ‚Ç¨45.3 billion (approximately $49.2 billion at\n",
        "        current exchange rates), compared to ‚Ç¨41.7 billion ($45.1 billion) in the prior year.\"\"\",\n",
        "        \"expected\": {\n",
        "            \"intl_revenue_eur_current\": 45.3, \"intl_revenue_usd_current\": 49.2,\n",
        "            \"intl_revenue_eur_prior\": 41.7, \"intl_revenue_usd_prior\": 45.1\n",
        "        },\n",
        "        \"difficulty\": \"hard\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"forex_02\",\n",
        "        \"category\": \"foreign_currency\",\n",
        "        \"text\": \"\"\"Revenue in constant currency grew 8%, while reported revenue in USD grew\n",
        "        only 3% due to foreign exchange headwinds of approximately $2.3 billion.\"\"\",\n",
        "        \"expected\": {\n",
        "            \"constant_currency_growth\": 8, \"reported_growth\": 3, \"fx_impact\": 2.3\n",
        "        },\n",
        "        \"difficulty\": \"hard\"\n",
        "    },\n",
        "\n",
        "    # === EDGE CASES: NEGATIVE VALUES (3 cases) ===\n",
        "    {\n",
        "        \"id\": \"negative_01\",\n",
        "        \"category\": \"negative_values\",\n",
        "        \"text\": \"Operating loss was $(2.3) billion in Q1, improving from a loss of $(3.7) billion in the prior year quarter.\",\n",
        "        \"expected\": {\"operating_loss_q1\": -2.3, \"operating_loss_prior\": -3.7},\n",
        "        \"difficulty\": \"hard\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"negative_02\",\n",
        "        \"category\": \"negative_values\",\n",
        "        \"text\": \"Free cash flow was negative $1.2 billion, compared to positive $3.4 billion last year.\",\n",
        "        \"expected\": {\"fcf_current\": -1.2, \"fcf_prior\": 3.4},\n",
        "        \"difficulty\": \"hard\"\n",
        "    },\n",
        "\n",
        "    # === EDGE CASES: PERCENTAGES AND BASIS POINTS (3 cases) ===\n",
        "    {\n",
        "        \"id\": \"percentage_01\",\n",
        "        \"category\": \"percentages\",\n",
        "        \"text\": \"\"\"Gross margin expanded 320 basis points to 45.7% from 42.5%.\n",
        "        Operating margin increased by 2.3 percentage points to 31.2%.\"\"\",\n",
        "        \"expected\": {\n",
        "            \"gross_margin_current\": 45.7, \"gross_margin_prior\": 42.5,\n",
        "            \"basis_points_change\": 320, \"operating_margin\": 31.2, \"pp_change\": 2.3\n",
        "        },\n",
        "        \"difficulty\": \"medium\"\n",
        "    },\n",
        "\n",
        "    # === EDGE CASES: RANGES AND GUIDANCE (3 cases) ===\n",
        "    {\n",
        "        \"id\": \"range_01\",\n",
        "        \"category\": \"ranges\",\n",
        "        \"text\": \"We expect Q1 2024 revenue between $88.0 billion and $92.0 billion, with gross margins of 44.0% to 45.0%.\",\n",
        "        \"expected\": {\n",
        "            \"revenue_guidance_low\": 88.0, \"revenue_guidance_high\": 92.0,\n",
        "            \"margin_guidance_low\": 44.0, \"margin_guidance_high\": 45.0\n",
        "        },\n",
        "        \"difficulty\": \"medium\"\n",
        "    },\n",
        "\n",
        "    # === EDGE CASES: FORMATTED NUMBERS (3 cases) ===\n",
        "    {\n",
        "        \"id\": \"format_01\",\n",
        "        \"category\": \"number_formats\",\n",
        "        \"text\": \"Revenue was $1,234.5 million in 2023, compared to $987.6 million in 2022.\",\n",
        "        \"expected\": {\"revenue_2023_millions\": 1234.5, \"revenue_2022_millions\": 987.6},\n",
        "        \"difficulty\": \"medium\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"format_02\",\n",
        "        \"category\": \"number_formats\",\n",
        "        \"text\": \"Total assets were $2.345 trillion, with cash and equivalents of $145.67 billion.\",\n",
        "        \"expected\": {\"total_assets_trillions\": 2.345, \"cash_billions\": 145.67},\n",
        "        \"difficulty\": \"hard\"\n",
        "    },\n",
        "\n",
        "    # === COMPLEX TABLES (2 cases) ===\n",
        "    {\n",
        "        \"id\": \"table_01\",\n",
        "        \"category\": \"tabular\",\n",
        "        \"text\": \"\"\"\n",
        "        Revenue by Region (in billions):\n",
        "        Americas: $169.7\n",
        "        Europe: $94.3\n",
        "        China: $72.6\n",
        "        Japan: $24.3\n",
        "        Rest of Asia Pacific: $29.1\n",
        "        \"\"\",\n",
        "        \"expected\": {\n",
        "            \"americas\": 169.7, \"europe\": 94.3, \"china\": 72.6,\n",
        "            \"japan\": 24.3, \"rest_asia\": 29.1\n",
        "        },\n",
        "        \"difficulty\": \"medium\"\n",
        "    }\n",
        "]\n",
        "\n",
        "def extract_metrics(model, text, model_name=\"gemini\"):\n",
        "    \"\"\"Extract metrics using specified model\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"You are a financial analyst extracting numerical data from SEC filings.\n",
        "\n",
        "    Extract ALL numerical financial metrics from this text and return as JSON.\n",
        "    Rules:\n",
        "    - Use descriptive keys (e.g., 'revenue_2023', 'gross_margin_q4')\n",
        "    - Include all numbers, percentages, and financial metrics\n",
        "    - Convert negative numbers properly (losses should be negative)\n",
        "    - Preserve decimal precision\n",
        "    - For ranges, extract both low and high values\n",
        "\n",
        "    Text: {text}\n",
        "\n",
        "    Return ONLY valid JSON, no other text.\"\"\"\n",
        "\n",
        "    try:\n",
        "        start = time.time()\n",
        "\n",
        "        if model_name == \"gemini\":\n",
        "            response = model.generate_content(prompt)\n",
        "            response_text = response.text\n",
        "        # Add GPT-4 and Claude here when you have API keys\n",
        "        # elif model_name == \"gpt4\":\n",
        "        #     response = openai_client.chat.completions.create(...)\n",
        "        # elif model_name == \"claude\":\n",
        "        #     response = anthropic_client.messages.create(...)\n",
        "        else:\n",
        "            return None, 0, \"Model not configured\"\n",
        "\n",
        "        latency = time.time() - start\n",
        "\n",
        "        # Parse response\n",
        "        if '```json' in response_text:\n",
        "            response_text = response_text.split('```json')[1].split('```')[0]\n",
        "        elif '```' in response_text:\n",
        "            response_text = response_text.split('```')[1].split('```')[0]\n",
        "\n",
        "        extracted = json.loads(response_text.strip())\n",
        "        return extracted, latency, None\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        return None, time.time() - start, f\"JSON Parse Error: {str(e)}\"\n",
        "    except Exception as e:\n",
        "        return None, time.time() - start, str(e)\n",
        "\n",
        "def calculate_accuracy(extracted, expected):\n",
        "    \"\"\"Calculate extraction accuracy with tolerance\"\"\"\n",
        "    if not extracted:\n",
        "        return 0, []\n",
        "\n",
        "    correct = 0\n",
        "    errors = []\n",
        "\n",
        "    for key, expected_val in expected.items():\n",
        "        found = False\n",
        "        # Look for matching value in extracted data\n",
        "        for ext_key, ext_val in extracted.items():\n",
        "            try:\n",
        "                if abs(float(ext_val) - float(expected_val)) < 0.5:\n",
        "                    correct += 1\n",
        "                    found = True\n",
        "                    break\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        if not found:\n",
        "            errors.append({\n",
        "                \"expected_key\": key,\n",
        "                \"expected_value\": expected_val,\n",
        "                \"status\": \"missing\"\n",
        "            })\n",
        "\n",
        "    accuracy = (correct / len(expected)) * 100 if expected else 0\n",
        "    return accuracy, errors\n",
        "\n",
        "def run_comprehensive_benchmark():\n",
        "    \"\"\"Run full benchmark suite\"\"\"\n",
        "\n",
        "    print(\"üöÄ COMPREHENSIVE SEC FILING BENCHMARK\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Testing {len(TEST_CASES)} cases across {len(set(tc['category'] for tc in TEST_CASES))} categories\")\n",
        "    print(f\"Timestamp: {datetime.now().isoformat()}\\n\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Test each case\n",
        "    for i, test_case in enumerate(TEST_CASES, 1):\n",
        "        print(f\"[{i}/{len(TEST_CASES)}] Testing {test_case['id']} ({test_case['category']})\")\n",
        "\n",
        "        # Test with Gemini\n",
        "        extracted, latency, error = extract_metrics(gemini_model, test_case['text'], \"gemini\")\n",
        "\n",
        "        if error:\n",
        "            accuracy = 0\n",
        "            error_details = [{\"error\": error}]\n",
        "        else:\n",
        "            accuracy, error_details = calculate_accuracy(extracted, test_case['expected'])\n",
        "\n",
        "        result = {\n",
        "            \"test_id\": test_case['id'],\n",
        "            \"category\": test_case['category'],\n",
        "            \"difficulty\": test_case['difficulty'],\n",
        "            \"model\": \"gemini-2.0-flash\",\n",
        "            \"accuracy\": accuracy,\n",
        "            \"latency\": latency,\n",
        "            \"extracted_count\": len(extracted) if extracted else 0,\n",
        "            \"expected_count\": len(test_case['expected']),\n",
        "            \"errors\": error_details,\n",
        "            \"success\": accuracy > 0\n",
        "        }\n",
        "\n",
        "        results.append(result)\n",
        "\n",
        "        # Progress indicator\n",
        "        status = \"‚úÖ\" if accuracy >= 80 else \"‚ö†Ô∏è\" if accuracy >= 50 else \"‚ùå\"\n",
        "        print(f\"  {status} Accuracy: {accuracy:.1f}% | Latency: {latency:.2f}s\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def analyze_results(results):\n",
        "    \"\"\"Generate comprehensive analysis\"\"\"\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä COMPREHENSIVE ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Overall metrics\n",
        "    print(\"\\n1. OVERALL PERFORMANCE\")\n",
        "    print(\"-\"*30)\n",
        "    print(f\"Total Tests: {len(df)}\")\n",
        "    print(f\"Success Rate: {(df['success'].sum()/len(df)*100):.1f}%\")\n",
        "    print(f\"Average Accuracy: {df['accuracy'].mean():.1f}%\")\n",
        "    print(f\"Average Latency: {df['latency'].mean():.3f}s\")\n",
        "    print(f\"Total Cost: ${len(df) * 0.000125:.4f}\")\n",
        "\n",
        "    # By category\n",
        "    print(\"\\n2. PERFORMANCE BY CATEGORY\")\n",
        "    print(\"-\"*30)\n",
        "    category_stats = df.groupby('category').agg({\n",
        "        'accuracy': 'mean',\n",
        "        'latency': 'mean',\n",
        "        'success': 'mean'\n",
        "    }).round(2)\n",
        "    print(category_stats)\n",
        "\n",
        "    # By difficulty\n",
        "    print(\"\\n3. PERFORMANCE BY DIFFICULTY\")\n",
        "    print(\"-\"*30)\n",
        "    difficulty_stats = df.groupby('difficulty').agg({\n",
        "        'accuracy': 'mean',\n",
        "        'latency': 'mean',\n",
        "        'success': 'mean'\n",
        "    }).round(2)\n",
        "    print(difficulty_stats)\n",
        "\n",
        "    # Error analysis\n",
        "    print(\"\\n4. ERROR ANALYSIS\")\n",
        "    print(\"-\"*30)\n",
        "    all_errors = []\n",
        "    for _, row in df.iterrows():\n",
        "        if row['errors']:\n",
        "            for error in row['errors']:\n",
        "                error['category'] = row['category']\n",
        "                all_errors.append(error)\n",
        "\n",
        "    if all_errors:\n",
        "        error_df = pd.DataFrame(all_errors)\n",
        "        if 'status' in error_df.columns:\n",
        "            print(\"Error Types:\")\n",
        "            print(error_df['status'].value_counts())\n",
        "    else:\n",
        "        print(\"No errors detected!\")\n",
        "\n",
        "    # Key findings for paper\n",
        "    print(\"\\n5. KEY FINDINGS FOR PAPER\")\n",
        "    print(\"-\"*30)\n",
        "    print(f\"\"\"\n",
        "    \"Gemini 2.0 Flash was evaluated on {len(df)} diverse SEC filing excerpts,\n",
        "    including edge cases such as restated financials, foreign currency\n",
        "    conversions, and negative values. The model achieved:\n",
        "\n",
        "    - Overall accuracy: {df['accuracy'].mean():.1f}%\n",
        "    - Success rate on complex cases: {df[df['difficulty']=='hard']['success'].mean()*100:.1f}%\n",
        "    - Average response time: {df['latency'].mean():.3f} seconds\n",
        "    - Highest performance on: {category_stats['accuracy'].idxmax()} ({category_stats['accuracy'].max():.1f}%)\n",
        "    - Most challenging category: {category_stats['accuracy'].idxmin()} ({category_stats['accuracy'].min():.1f}%)\n",
        "\n",
        "    Cost efficiency: ${len(df) * 0.000125 * 1000 / len(df):.2f} per 1,000 documents\"\n",
        "    \"\"\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# RUN THE COMPREHENSIVE BENCHMARK\n",
        "results = run_comprehensive_benchmark()\n",
        "results_df = analyze_results(results)\n",
        "\n",
        "# Save results\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "results_df.to_csv(f\"sec_benchmark_results_{timestamp}.csv\", index=False)\n",
        "with open(f\"sec_benchmark_raw_{timestamp}.json\", 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(f\"\\nüíæ Results saved to sec_benchmark_results_{timestamp}.csv\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dF9EuzK7RXg",
        "outputId": "0015da83-2d6d-4d02-b887-122856d1894a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ COMPREHENSIVE SEC FILING BENCHMARK\n",
            "============================================================\n",
            "Testing 18 cases across 13 categories\n",
            "Timestamp: 2025-10-04T15:57:20.699313\n",
            "\n",
            "[1/18] Testing basic_01 (basic_revenue)\n",
            "  ‚ùå Accuracy: 0.0% | Latency: 1.04s\n",
            "[2/18] Testing basic_02 (basic_revenue)\n",
            "  ‚ùå Accuracy: 0.0% | Latency: 0.81s\n",
            "[3/18] Testing basic_03 (basic_margins)\n",
            "  ‚úÖ Accuracy: 100.0% | Latency: 0.61s\n",
            "[4/18] Testing basic_04 (basic_earnings)\n",
            "  ‚úÖ Accuracy: 100.0% | Latency: 0.43s\n",
            "[5/18] Testing basic_05 (basic_segments)\n",
            "  ‚úÖ Accuracy: 100.0% | Latency: 0.58s\n",
            "[6/18] Testing complex_01 (complex_multi)\n",
            "  ‚ùå Accuracy: 44.4% | Latency: 1.39s\n",
            "[7/18] Testing complex_02 (complex_quarterly)\n",
            "  ‚ùå Accuracy: 0.0% | Latency: 0.95s\n",
            "[8/18] Testing restatement_01 (restated)\n",
            "  ‚ùå Accuracy: 0.0% | Latency: 0.65s\n",
            "[9/18] Testing restatement_02 (restated)\n",
            "  ‚ùå Accuracy: 0.0% | Latency: 0.72s\n",
            "[10/18] Testing forex_01 (foreign_currency)\n",
            "  ‚úÖ Accuracy: 100.0% | Latency: 0.83s\n",
            "[11/18] Testing forex_02 (foreign_currency)\n",
            "  ‚ùå Accuracy: 0.0% | Latency: 0.55s\n",
            "[12/18] Testing negative_01 (negative_values)\n",
            "  ‚ùå Accuracy: 0.0% | Latency: 0.71s\n",
            "[13/18] Testing negative_02 (negative_values)\n",
            "  ‚ùå Accuracy: 0.0% | Latency: 0.64s\n",
            "[14/18] Testing percentage_01 (percentages)\n",
            "  ‚ùå Accuracy: 40.0% | Latency: 0.77s\n",
            "[15/18] Testing range_01 (ranges)\n",
            "  ‚úÖ Accuracy: 100.0% | Latency: 0.76s\n",
            "[16/18] Testing format_01 (number_formats)\n",
            "  ‚úÖ Accuracy: 100.0% | Latency: 0.53s\n",
            "[17/18] Testing format_02 (number_formats)\n",
            "  ‚ùå Accuracy: 0.0% | Latency: 0.70s\n",
            "[18/18] Testing table_01 (tabular)\n",
            "  ‚úÖ Accuracy: 100.0% | Latency: 0.94s\n",
            "\n",
            "============================================================\n",
            "üìä COMPREHENSIVE ANALYSIS\n",
            "============================================================\n",
            "\n",
            "1. OVERALL PERFORMANCE\n",
            "------------------------------\n",
            "Total Tests: 18\n",
            "Success Rate: 50.0%\n",
            "Average Accuracy: 43.6%\n",
            "Average Latency: 0.756s\n",
            "Total Cost: $0.0023\n",
            "\n",
            "2. PERFORMANCE BY CATEGORY\n",
            "------------------------------\n",
            "                   accuracy  latency  success\n",
            "category                                     \n",
            "basic_earnings       100.00     0.43      1.0\n",
            "basic_margins        100.00     0.61      1.0\n",
            "basic_revenue          0.00     0.93      0.0\n",
            "basic_segments       100.00     0.58      1.0\n",
            "complex_multi         44.44     1.39      1.0\n",
            "complex_quarterly      0.00     0.95      0.0\n",
            "foreign_currency      50.00     0.69      0.5\n",
            "negative_values        0.00     0.67      0.0\n",
            "number_formats        50.00     0.61      0.5\n",
            "percentages           40.00     0.77      1.0\n",
            "ranges               100.00     0.76      1.0\n",
            "restated               0.00     0.69      0.0\n",
            "tabular              100.00     0.94      1.0\n",
            "\n",
            "3. PERFORMANCE BY DIFFICULTY\n",
            "------------------------------\n",
            "            accuracy  latency  success\n",
            "difficulty                            \n",
            "easy           60.00     0.69     0.60\n",
            "hard           14.29     0.69     0.14\n",
            "medium         64.07     0.89     0.83\n",
            "\n",
            "4. ERROR ANALYSIS\n",
            "------------------------------\n",
            "Error Types:\n",
            "status\n",
            "missing    35\n",
            "Name: count, dtype: int64\n",
            "\n",
            "5. KEY FINDINGS FOR PAPER\n",
            "------------------------------\n",
            "\n",
            "    \"Gemini 2.0 Flash was evaluated on 18 diverse SEC filing excerpts,\n",
            "    including edge cases such as restated financials, foreign currency \n",
            "    conversions, and negative values. The model achieved:\n",
            "    \n",
            "    - Overall accuracy: 43.6%\n",
            "    - Success rate on complex cases: 14.3%\n",
            "    - Average response time: 0.756 seconds\n",
            "    - Highest performance on: basic_earnings (100.0%)\n",
            "    - Most challenging category: basic_revenue (0.0%)\n",
            "    \n",
            "    Cost efficiency: $0.13 per 1,000 documents\"\n",
            "    \n",
            "\n",
            "üíæ Results saved to sec_benchmark_results_20251004_155734.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Title: \"The Limits of Large Language Models in Financial Document Analysis:\n",
        "A Comprehensive Benchmark of SEC Filing Extraction\"\n",
        "\n",
        "## Abstract\n",
        "\"While LLMs show promise for financial analysis, our benchmark of 18 diverse\n",
        "SEC filing scenarios reveals significant limitations. Gemini 2.0 Flash achieved\n",
        "100% accuracy on basic revenue extraction but 0% on foreign currency conversions,\n",
        "negative values, and restated financials - critical elements in financial reporting.\"\n",
        "\n",
        "## Key Message\n",
        "\"Our findings reveal a critical gap: LLMs excel at simple pattern matching\n",
        "but fail at the nuanced understanding required for production financial systems.\n",
        "This suggests the need for specialized financial LLMs or hybrid approaches.\"\n"
      ],
      "metadata": {
        "id": "Zn2hEW_t84ho"
      }
    }
  ]
}